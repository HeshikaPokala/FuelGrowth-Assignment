{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6badf9d-a2f5-4596-adfe-e0aba16cb384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import DBSCAN\n",
    "from deepface import DeepFace\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "import os\n",
    "import warnings\n",
    "import dlib\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load dataset\n",
    "file_path = 'Assignment Data.xlsx'\n",
    "df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
    "df = df[['Video URL', 'Performance']]\n",
    "\n",
    "# Detect faces in frames\n",
    "def detect_faces(frame):\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "    faces = detector(gray)\n",
    "    return [frame[face.top():face.bottom(), face.left():face.right()] for face in faces if face.width() > 0 and face.height() > 0]\n",
    "\n",
    "# Initialize embeddings and metadata storage\n",
    "face_embeddings = []\n",
    "face_metadata = []\n",
    "\n",
    "# Directory to save representative face images\n",
    "os.makedirs('cluster_faces', exist_ok=True)\n",
    "\n",
    "# Function to calculate cosine similarity between embeddings\n",
    "def get_cosine_similarity(embedding1, embedding2):\n",
    "    return cosine_similarity([embedding1], [embedding2])[0][0]\n",
    "\n",
    "# Process videos\n",
    "for index, row in df.iterrows():\n",
    "    video_url = row['Video URL']\n",
    "    performance = row['Performance']\n",
    "\n",
    "    video_capture = cv2.VideoCapture(video_url)\n",
    "    if not video_capture.isOpened():\n",
    "        print(f\"Skipping inaccessible video: {video_url}\")\n",
    "        continue\n",
    "\n",
    "    frame_count = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if frame_count == 0:\n",
    "        print(f\"Skipping empty video: {video_url}\")\n",
    "        continue\n",
    "\n",
    "    step = max(frame_count // 50, 1)  # Sample more frames by reducing step size\n",
    "    for frame_num in range(0, frame_count, step):\n",
    "        video_capture.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "        success, frame = video_capture.read()\n",
    "        if not success or frame is None:\n",
    "            continue\n",
    "\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        faces = detect_faces(rgb_frame)\n",
    "\n",
    "        if not faces:\n",
    "            print(f\"No faces detected in frame {frame_num} of video: {video_url}\")\n",
    "            continue\n",
    "\n",
    "        for face in faces:\n",
    "            try:\n",
    "                # Get facial embeddings\n",
    "                embeddings = DeepFace.represent(face, model_name='Facenet', enforce_detection=False, detector_backend='opencv')\n",
    "                if embeddings:\n",
    "                    # Analyze the emotion\n",
    "                    emotion_analysis = DeepFace.analyze(face, actions=['emotion'], enforce_detection=False)\n",
    "                    dominant_emotion = emotion_analysis[0]['dominant_emotion']\n",
    "\n",
    "                    # Append face embedding, performance, and emotion to metadata\n",
    "                    face_embeddings.append(embeddings[0]['embedding'])\n",
    "                    face_metadata.append({'video_url': video_url, 'performance': performance, \n",
    "                                          'face_image': face, 'emotion': dominant_emotion, \n",
    "                                          'embedding': embeddings[0]['embedding']})  # Store the embedding\n",
    "            except ValueError as e:\n",
    "                print(f\"Failed to extract embedding: {e}\")\n",
    "                continue\n",
    "\n",
    "    video_capture.release()\n",
    "\n",
    "# Clustering step\n",
    "if face_embeddings:\n",
    "    face_embeddings = np.array(face_embeddings)\n",
    "    n_components = min(5, len(face_embeddings), face_embeddings.shape[1])\n",
    "    pca = PCA(n_components=n_components)\n",
    "    reduced_embeddings = pca.fit_transform(face_embeddings)\n",
    "\n",
    "    dbscan = DBSCAN(eps=0.3, min_samples=2).fit(reduced_embeddings)\n",
    "    unique_labels = dbscan.labels_\n",
    "\n",
    "    # Combine clustering results with metadata\n",
    "    metadata_df = pd.DataFrame(face_metadata)\n",
    "    metadata_df['cluster'] = unique_labels\n",
    "\n",
    "    # Eliminate duplicate clusters based on cosine similarity between embeddings\n",
    "    unique_faces = {}\n",
    "    for cluster in unique_labels:\n",
    "        cluster_faces = metadata_df[metadata_df['cluster'] == cluster]\n",
    "\n",
    "        # Process the cluster (even if it's noise, i.e., -1)\n",
    "        representative_face = cluster_faces.iloc[0]  # Start with the first face in the cluster\n",
    "        is_duplicate = False\n",
    "\n",
    "        # Compare this face embedding with other face embeddings in the unique_faces dictionary to eliminate duplicates\n",
    "        for _, other_face in unique_faces.items():\n",
    "            similarity = get_cosine_similarity(representative_face['embedding'], other_face['embedding'])\n",
    "            if similarity > 0.95:  # 0.95 is a threshold for similarity, adjust as needed\n",
    "                is_duplicate = True\n",
    "                break\n",
    "\n",
    "        # If not a duplicate, add this face to the unique faces\n",
    "        if not is_duplicate:\n",
    "            unique_faces[cluster] = representative_face\n",
    "\n",
    "    # Create a DataFrame for unique faces\n",
    "    unique_faces_df = pd.DataFrame(unique_faces).T\n",
    "\n",
    "    # Calculate average performance for each cluster\n",
    "    performance_stats = unique_faces_df.groupby('cluster').agg(\n",
    "        avg_performance=('performance', 'mean')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Sort clusters by descending average performance\n",
    "    performance_stats = performance_stats.sort_values(by='avg_performance', ascending=False)\n",
    "\n",
    "    # Save results in a Word document\n",
    "    document = Document()\n",
    "    document.add_heading('Cluster Performance Report', 0)\n",
    "\n",
    "    table = document.add_table(rows=1, cols=4)  # Add an extra column for emotion\n",
    "    hdr_cells = table.rows[0].cells\n",
    "    hdr_cells[0].text = 'Cluster Number'\n",
    "    hdr_cells[1].text = 'Average Performance'\n",
    "    hdr_cells[2].text = 'Face Image'\n",
    "    hdr_cells[3].text = 'Dominant Emotion'  # New column for emotion\n",
    "\n",
    "    for _, row in performance_stats.iterrows():\n",
    "        cluster = row['cluster']\n",
    "        avg_performance = row['avg_performance']\n",
    "\n",
    "        cluster_faces = metadata_df[metadata_df['cluster'] == cluster]\n",
    "        if not cluster_faces.empty:\n",
    "            # Save the first representative face from the cluster\n",
    "            face_image = cluster_faces.iloc[0]['face_image']\n",
    "            face_filename = f'cluster_faces/cluster_{cluster}_face.jpg'\n",
    "            cv2.imwrite(face_filename, cv2.cvtColor(face_image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "            # Get the emotion of the representative face\n",
    "            dominant_emotion = cluster_faces.iloc[0]['emotion']\n",
    "\n",
    "            # Add data to the table\n",
    "            row_cells = table.add_row().cells\n",
    "            row_cells[0].text = str(cluster)\n",
    "            row_cells[1].text = f'{avg_performance:.2f}'\n",
    "            paragraph = row_cells[2].paragraphs[0]\n",
    "            run = paragraph.add_run()\n",
    "            run.add_picture(face_filename, width=Inches(1.5))\n",
    "            row_cells[3].text = dominant_emotion  # Add emotion text to the table\n",
    "\n",
    "    # Save the Word document\n",
    "    document.save('cluster_performance_report.docx')\n",
    "    print(\"Results saved to 'cluster_performance_report.docx'\")\n",
    "\n",
    "else:\n",
    "    print(\"No faces detected.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
